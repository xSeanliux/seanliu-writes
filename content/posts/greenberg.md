---
title: "A Statistical Look at Greenberg's Universals"
author: "Sean Liu"
date: 2022-08-12T03:13:37-07:00
categories: ['english', 'linguistics', 'greenberg']
draft: true
---
# Introduction 

*Language* is a fickle thing. On one hand, it's "easy": presumably, you and all the people you know speak at least one language. Many people speak more than one! But on the other, it's incredibly intricate and complex: even within a language, the choice of words can subtly influence the tone and flow of a sentence, not to mention all the nooks and crannies of varying dialects. Across languages and language families, this difference seems to multiply thousandsfold: in some languages, "I eat an apple" becomes (when literally translated) "I apple eat," each with their own set of sounds and ways to form sentences. Therefore, it's a natural question to ask: what do languages have in common? Specifically, what do *human* languages have in common that are not also shared by *animal* calls and grunts? 

This leads to the Chomskian theory of Universal Grammar, which postulates that each and every human is gifted with an innate abstract ability for language, from which all language all stem from this central source - realisations of this invisible Form. More concretely, it has been proposed that *recursion*, the ability to embed parts of language inside itself, is the unifying and differentiating factor between human languages and animal ones (though even this is disputed: see Daniel Everett's work on Pirah√£ linguistics). 

Such *Universals* (facts that are true across all or most languages) are thus invaluable, because they potentially hold clues to the inner workings of our linguistic faculties. Here, we aim to introduce Greenberg's Universals and to perform a statistical verification of the proposed Universals.

# What are Greenberg's Universals? 

